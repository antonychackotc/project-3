{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWtBE9h+HzowgYQu7uid2q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonychackotc/project-3/blob/main/part_4_multiple_disease_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part - 4 : - Streamlit application**"
      ],
      "metadata": {
        "id": "EV8BAvIM4Wpp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Displays predicted diseases with their respective probabilities and risk levels**"
      ],
      "metadata": {
        "id": "5ZuCamzl4iXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cWjdMBA_k-5t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sQikviVm4TFL"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv('/content/df1_balanced_dataset.csv')  #after SMOTE method only its shows balanced dataset\n",
        "df2=pd.read_csv('/content/df2_encoded.csv')  #after Encoding before SMOTE its shows balanced dataset\n",
        "df3=pd.read_csv('/content/df3_balanced_dataset.csv') #befor SMOTE its Shows Accuracy after SMOTE method only its shows balanced dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit\n",
        "!pip install -q pyngrok\n",
        "!pip install -q localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mxr4G-uA5Vvc",
        "outputId": "b5d310e2-5a03-4506-ed64-4bf11d73d9b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: Could not find a version that satisfies the requirement localtunnel (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for localtunnel\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py"
      ],
      "metadata": {
        "id": "LzdO_gfl1aBB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16eb950c-417f-4204-fc73-5cd107c552a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app1.py\n",
        "\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import streamlit as st\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import (\n",
        "#     accuracy_score, precision_score, recall_score, f1_score, r2_score,\n",
        "#     mean_absolute_error, mean_squared_error\n",
        "# )\n",
        "# from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
        "# from sklearn.svm import SVR, SVC\n",
        "# from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "# from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "# from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "# # Create sample datasets\n",
        "# df1=pd.read_csv('/content/df1_balanced_dataset.csv')\n",
        "# df2=pd.read_csv('/content/df2_encoded.csv')\n",
        "# df3=pd.read_csv('/content/df3_balanced_dataset.csv')\n",
        "\n",
        "# # Map datasets to sidebar selection\n",
        "# data_options = {\"Indian Liver Patient\": df1, \"Kidney Disease\": df2, \"Parkinsons\": df3}\n",
        "\n",
        "# # Streamlit UI\n",
        "# st.title(\"Automated Model Selection with Future Prediction\")\n",
        "\n",
        "# # Sidebar for dataset selection\n",
        "# selected_dataset_name = st.sidebar.selectbox(\"Select a Dataset:\", list(data_options.keys()))\n",
        "# data = data_options[selected_dataset_name]\n",
        "# st.sidebar.write(f\"**Preview of {selected_dataset_name}:**\")\n",
        "# st.sidebar.write(data.head())\n",
        "\n",
        "# # Tabs for better navigation\n",
        "# tabs = st.tabs([\"Data Analysis\", \"Model Evaluation\", \"Future Prediction\"])\n",
        "\n",
        "# # Function to evaluate regression models with detailed metrics\n",
        "# def evaluate_regression(model, X_test, y_test, X_train):\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     mae = mean_absolute_error(y_test, y_pred)\n",
        "#     mse = mean_squared_error(y_test, y_pred)\n",
        "#     rmse = np.sqrt(mse)\n",
        "#     r2 = r2_score(y_test, y_pred)\n",
        "#     adj_r2 = 1 - (1 - r2) * (len(y_test) - 1) / (X_train.shape[0] - X_train.shape[1] - 1)\n",
        "#     return {\n",
        "#         \"MAE\": mae,\n",
        "#         \"MSE\": mse,\n",
        "#         \"RMSE\": rmse,\n",
        "#         \"R2\": r2,\n",
        "#         \"Adjusted R2\": adj_r2\n",
        "#     }\n",
        "\n",
        "# # Function to evaluate classification models with detailed metrics\n",
        "# def evaluate_classification(model, X_test, y_test, balance):\n",
        "#     y_pred = model.predict(X_test)\n",
        "#     accuracy = accuracy_score(y_test, y_pred)\n",
        "#     metrics = {\"Accuracy\": accuracy}\n",
        "\n",
        "#     if not balance:  # Unbalanced data\n",
        "#         precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "#         recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "#         f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "#         metrics.update({\"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1})\n",
        "\n",
        "#     return metrics\n",
        "\n",
        "# # Function to apply a single model\n",
        "# def apply_single_model(X_train, X_test, y_train, y_test, model_name, task_type, balance):\n",
        "#     model_map = {\n",
        "#         \"Linear Regression\": LinearRegression(),\n",
        "#         \"Ridge Regression\": Ridge(),\n",
        "#         \"Lasso Regression\": Lasso(),\n",
        "#         \"ElasticNet Regression\": ElasticNet(),\n",
        "#         \"SVM Regression\": SVR(),\n",
        "#         \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "#         \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "#         \"Boosting Regressor\": GradientBoostingRegressor(),\n",
        "#         \"KNN Regressor\": KNeighborsRegressor(),\n",
        "#         \"Logistic Regression\": LogisticRegression(),\n",
        "#         \"SVM Classifier\": SVC(),\n",
        "#         \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "#         \"Random Forest Classifier\": RandomForestClassifier(),\n",
        "#         \"Boosting Classifier\": GradientBoostingClassifier(),\n",
        "#         \"KNN Classifier\": KNeighborsClassifier(),\n",
        "#         \"Naive Bayes Classifier\": GaussianNB(),\n",
        "#     }\n",
        "\n",
        "#     if model_name == \"Polynomial Regression\":\n",
        "#         poly = PolynomialFeatures(degree=2)\n",
        "#         X_train_poly = poly.fit_transform(X_train)\n",
        "#         X_test_poly = poly.transform(X_test)\n",
        "#         lin_reg = LinearRegression()\n",
        "#         lin_reg.fit(X_train_poly, y_train)\n",
        "#         metrics = evaluate_regression(lin_reg, X_test_poly, y_test, X_train_poly)\n",
        "#         trained_model = lin_reg\n",
        "#     else:\n",
        "#         model = model_map[model_name]\n",
        "#         model.fit(X_train, y_train)\n",
        "#         if task_type == 'regression':\n",
        "#             metrics = evaluate_regression(model, X_test, y_test, X_train)\n",
        "#         else:\n",
        "#             metrics = evaluate_classification(model, X_test, y_test, balance)\n",
        "#         trained_model = model\n",
        "\n",
        "#     return trained_model, metrics\n",
        "\n",
        "# # Data Analysis Tab\n",
        "# with tabs[0]:\n",
        "#     st.header(\"Data Analysis\")\n",
        "#     st.write(\"Dataset Preview:\", data.head())\n",
        "\n",
        "#     y_col = st.selectbox(\"Select the target column:\", data.columns)\n",
        "#     if y_col:\n",
        "#         y = data[y_col]\n",
        "#         unique_values = y.nunique()\n",
        "\n",
        "#         # Determine if the data is continuous or discrete\n",
        "#         if y.dtype in [np.int64, np.float64]:\n",
        "#             if unique_values > 20:\n",
        "#                 inferred_task_type = 'regression'\n",
        "#                 data_type = \"Continuous\"\n",
        "#             else:\n",
        "#                 inferred_task_type = 'classification'\n",
        "#                 data_type = \"Discrete\"\n",
        "#         else:\n",
        "#             inferred_task_type = 'classification'\n",
        "#             data_type = \"Discrete\"\n",
        "\n",
        "#         balance = inferred_task_type == 'classification' and (y.value_counts(normalize=True).max() <= 0.7)\n",
        "\n",
        "#         st.write(f\"**Target Column Data Type:** {data_type}\")\n",
        "#         st.write(f\"**Inferred Task Type:** {inferred_task_type}\")\n",
        "#         st.write(f\"**Data Balance:** {'Balanced' if balance else 'Unbalanced'}\")\n",
        "#         if inferred_task_type == 'regression':\n",
        "#             st.write(\"**Suggested Model:** Linear Regression or Random Forest Regressor\")\n",
        "#         else:\n",
        "#             st.write(\"**Suggested Model:** Random Forest Classifier or Logistic Regression\")\n",
        "\n",
        "# # Model Evaluation Tab\n",
        "# with tabs[1]:\n",
        "#     st.header(\"Model Evaluation\")\n",
        "#     X_cols = st.multiselect(\"Select feature columns:\", [col for col in data.columns if col != y_col])\n",
        "#     if not X_cols:\n",
        "#         st.warning(\"Please select at least one feature column.\")\n",
        "#     else:\n",
        "#         X = data[X_cols]\n",
        "#         y = data[y_col]\n",
        "\n",
        "#         task_type = st.radio(\"Confirm Task Type:\", [\"regression\", \"classification\"])\n",
        "#         balance = task_type == 'classification' and (y.value_counts(normalize=True).max() <= 0.7)\n",
        "\n",
        "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#         model_list = [\n",
        "#             \"Linear Regression\", \"Polynomial Regression\", \"Ridge Regression\", \"Lasso Regression\",\n",
        "#             \"ElasticNet Regression\", \"SVM Regression\", \"Decision Tree Regressor\",\n",
        "#             \"Random Forest Regressor\", \"Boosting Regressor\", \"KNN Regressor\"\n",
        "#         ] if task_type == 'regression' else [\n",
        "#             \"Logistic Regression\", \"SVM Classifier\", \"Decision Tree Classifier\",\n",
        "#             \"Random Forest Classifier\", \"Boosting Classifier\", \"KNN Classifier\",\n",
        "#             \"Naive Bayes Classifier\"\n",
        "#         ]\n",
        "\n",
        "#         selected_model = st.selectbox(\"Select a model to evaluate:\", model_list)\n",
        "#         if st.button(\"Run Selected Model\"):\n",
        "#             trained_model, metrics = apply_single_model(X_train, X_test, y_train, y_test, selected_model, task_type, balance)\n",
        "#             st.session_state[\"trained_model\"] = trained_model  # Save the trained model to session state\n",
        "#             st.session_state[\"X_cols\"] = X_cols  # Save selected feature columns\n",
        "\n",
        "#             st.write(f\"Model {selected_model} Performance Metrics:\")\n",
        "#             for metric, value in metrics.items():\n",
        "#                               st.write(f\"- {metric}: {value:.2f}\")\n",
        "\n",
        "#      # Future Prediction Tab\n",
        "# with tabs[2]:\n",
        "#     st.header(\"Future Prediction\")\n",
        "\n",
        "#     if \"trained_model\" in st.session_state and \"X_cols\" in st.session_state:\n",
        "#         st.write(\"Provide data for prediction using the selected features.\")\n",
        "\n",
        "#         # Generate input fields dynamically for prediction\n",
        "#         input_data = {col: st.number_input(f\"Enter value for {col}:\", value=0.0) for col in st.session_state[\"X_cols\"]}\n",
        "#         input_df = pd.DataFrame([input_data])  # Convert input to DataFrame\n",
        "#         st.write(\"Input Data Preview:\", input_df)\n",
        "\n",
        "#         # Generate prediction\n",
        "#         if st.button(\"Generate Prediction\"):\n",
        "#             try:\n",
        "#                 trained_model = st.session_state[\"trained_model\"]\n",
        "#                 predictions = trained_model.predict(input_df)\n",
        "#                 st.write(\"Predictions:\", predictions)\n",
        "#             except Exception as e:\n",
        "#                 st.error(f\"An error occurred during prediction: {e}\")\n",
        "#     else:\n",
        "#         st.warning(\"Please evaluate a model in the 'Model Evaluation' tab before generating predictions.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IHzP35TzA16P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app1.py\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score, r2_score,\n",
        "    mean_absolute_error, mean_squared_error\n",
        ")\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.svm import SVR, SVC\n",
        "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create sample datasets\n",
        "df1 = pd.read_csv('/content/df1_balanced_dataset.csv')\n",
        "df2 = pd.read_csv('/content/df2_encoded.csv')\n",
        "df3 = pd.read_csv('/content/df3_balanced_dataset.csv')\n",
        "\n",
        "# Map datasets to sidebar selection\n",
        "data_options = {\"Indian Liver Patient\": df1, \"Kidney Disease\": df2, \"Parkinsons\": df3}\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"Automated Model Selection with Future Prediction\")\n",
        "\n",
        "# Sidebar for dataset selection\n",
        "selected_dataset_name = st.sidebar.selectbox(\"Select a Dataset:\", list(data_options.keys()))\n",
        "data = data_options[selected_dataset_name]\n",
        "st.sidebar.write(f\"**Preview of {selected_dataset_name}:**\")\n",
        "st.sidebar.write(data.head())\n",
        "\n",
        "# Tabs for better navigation\n",
        "tabs = st.tabs([\"Data Analysis\", \"Model Evaluation\", \"Future Prediction\"])\n",
        "\n",
        "# Normal ranges for liver function tests\n",
        "liver_function_reference = {\n",
        "    \"Total Bilirubin\": \"Normal range (0.3–1.2 mg/dL)\",\n",
        "    \"Direct Bilirubin\": \"Normal range (0.0–0.3 mg/dL)\",\n",
        "    \"Alkaline Phosphatase\": \"Normal range (44–147 U/L)\",\n",
        "    \"Alanine Aminotransferase\": \"Normal range (7–56 U/L)\",\n",
        "    \"Aspartate Aminotransferase\": \"Normal range (10–40 U/L)\",\n",
        "    \"Total Proteins\": \"Normal range (6.0–8.3 g/dL)\",\n",
        "    \"Albumin\": \"Normal range (3.5–5.0 g/dL)\",\n",
        "    \"Albumin-to-Globulin Ratio\": \"Normal range (~1.0–2.1)\"\n",
        "}\n",
        "# Normal ranges for CKD-related parameters\n",
        "kidney_disease_reference = {\n",
        "    \"Age\": \"NA (Used to assess CKD risk; risk increases with age)\",\n",
        "    \"Blood Pressure (BP)\": \"90/60 mmHg to 120/80 mmHg (High BP is a common cause/complication of CKD)\",\n",
        "    \"Specific Gravity (SG)\": \"1.010–1.030 (Indicates kidney's concentrating ability)\",\n",
        "    \"Albumin (AL)\": \"<30 mg/day (urine, High levels indicate kidney damage)\",\n",
        "    \"Sugar (SU)\": \"Negative (Glucose in urine indicates diabetes, a CKD cause)\",\n",
        "    \"Red Blood Cells (RBC)\": \"0–2/hpf (Presence in urine indicates glomerular damage)\",\n",
        "    \"Pus Cells (PC)\": \"0–5/hpf (High levels suggest infection or inflammation)\",\n",
        "    \"Pus Cell Casts (PCC)\": \"Absent (Presence indicates tubular/glomerular damage)\",\n",
        "    \"Bacteria (BA)\": \"Absent (Presence suggests urinary tract infection)\",\n",
        "    \"Blood Glucose Random (BGR)\": \"70–140 mg/dL (High levels indicate diabetes)\",\n",
        "    \"Blood Urea (BU)\": \"7–20 mg/dL (Elevated in CKD due to impaired filtration)\",\n",
        "    \"Serum Creatinine (SC)\": \"0.6–1.2 mg/dL (male), 0.5–1.1 mg/dL (female) (Elevated levels indicate reduced kidney function)\",\n",
        "    \"Sodium (SOD)\": \"135–145 mmol/L (Electrolyte imbalance common in CKD)\",\n",
        "    \"Potassium (POT)\": \"3.5–5.0 mmol/L (Hyperkalemia common in CKD)\",\n",
        "    \"Hemoglobin (HEMO)\": \"12–16 g/dL (female), 13–17 g/dL (male) (Low levels indicate anemia)\",\n",
        "    \"Packed Cell Volume (PCV)\": \"35–45% (Low PCV indicates anemia in CKD)\",\n",
        "    \"White Blood Cell Count (WC)\": \"4,000–11,000/µL (May indicate infection/inflammation)\",\n",
        "    \"Red Blood Cell Count (RC)\": \"4.5–6.0 million/µL (Low levels indicate anemia)\",\n",
        "    \"Hypertension (HTN)\": \"Absent (Presence increases CKD risk/progression)\",\n",
        "    \"Diabetes Mellitus (DM)\": \"Absent (Leading cause of CKD)\",\n",
        "    \"Coronary Artery Disease (CAD)\": \"Absent (Risk factor/complication of CKD)\",\n",
        "    \"Appetite\": \"Normal (Poor appetite common in advanced CKD)\",\n",
        "    \"Pedal Edema (PE)\": \"Absent (Indicates fluid retention)\",\n",
        "    \"Anemia (ANE)\": \"Absent (Common in CKD due to low erythropoietin production)\"\n",
        "}\n",
        "# Reference ranges for Parkinson's dataset parameters\n",
        "parkinsons_reference = {\n",
        "    \"MDVP:Fo(Hz)\": \"Fundamental frequency (85–255 Hz)\",\n",
        "    \"MDVP:Fhi(Hz)\": \"Maximum fundamental frequency (100–260 Hz)\",\n",
        "    \"MDVP:Flo(Hz)\": \"Minimum fundamental frequency (75–240 Hz)\",\n",
        "    \"MDVP:Jitter(%)\": \"Jitter (local, normal range ~0.0–0.02%)\",\n",
        "    \"MDVP:Jitter(Abs)\": \"Absolute jitter (0.0–0.0001)\",\n",
        "    \"MDVP:RAP\": \"Relative amplitude perturbation (0.0–0.02)\",\n",
        "    \"MDVP:PPQ\": \"Five-point period perturbation quotient (0.0–0.02)\",\n",
        "    \"Jitter:DDP\": \"Difference of differences of pitch period (0.0–0.06)\",\n",
        "    \"MDVP:Shimmer\": \"Shimmer (local, normal range ~0.0–0.03)\",\n",
        "    \"MDVP:Shimmer(dB)\": \"Shimmer in decibels (0.0–0.35 dB)\",\n",
        "    \"Shimmer:APQ3\": \"Three-point amplitude perturbation quotient (0.0–0.02)\",\n",
        "    \"Shimmer:APQ5\": \"Five-point amplitude perturbation quotient (0.0–0.03)\",\n",
        "    \"MDVP:APQ\": \"Amplitude perturbation quotient (0.0–0.04)\",\n",
        "    \"Shimmer:DDA\": \"Difference of differences of amplitude (0.0–0.09)\",\n",
        "    \"NHR\": \"Noise-to-harmonics ratio (0.0–0.3)\",\n",
        "    \"HNR\": \"Harmonics-to-noise ratio (normal range >20 dB)\",\n",
        "    \"RPDE\": \"Recurrence period density entropy (0.2–0.6)\",\n",
        "    \"DFA\": \"Detrended fluctuation analysis (0.5–0.8)\",\n",
        "    \"spread1\": \"Signal fractal scaling exponent (normal range ~ -7 to -4)\",\n",
        "    \"spread2\": \"Signal variation (normal range ~ -0.5 to 0.5)\",\n",
        "    \"D2\": \"Signal complexity (normal range ~2–3)\",\n",
        "    \"PPE\": \"Pitch period entropy (normal range ~0.0–0.8)\"\n",
        "}\n",
        "\n",
        "# Function to evaluate regression models with detailed metrics\n",
        "def evaluate_regression(model, X_test, y_test, X_train):\n",
        "    y_pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    adj_r2 = 1 - (1 - r2) * (len(y_test) - 1) / (X_train.shape[0] - X_train.shape[1] - 1)\n",
        "    return {\n",
        "        \"MAE\": mae,\n",
        "        \"MSE\": mse,\n",
        "        \"RMSE\": rmse,\n",
        "        \"R2\": r2,\n",
        "        \"Adjusted R2\": adj_r2\n",
        "    }\n",
        "\n",
        "# Function to evaluate classification models with detailed metrics\n",
        "def evaluate_classification(model, X_test, y_test, balance):\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    metrics = {\"Accuracy\": accuracy}\n",
        "\n",
        "    if not balance:  # Unbalanced data\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        metrics.update({\"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1})\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Function to apply a single model\n",
        "def apply_single_model(X_train, X_test, y_train, y_test, model_name, task_type, balance):\n",
        "    model_map = {\n",
        "        \"Linear Regression\": LinearRegression(),\n",
        "        \"Ridge Regression\": Ridge(),\n",
        "        \"Lasso Regression\": Lasso(),\n",
        "        \"ElasticNet Regression\": ElasticNet(),\n",
        "        \"SVM Regression\": SVR(),\n",
        "        \"Decision Tree Regressor\": DecisionTreeRegressor(),\n",
        "        \"Random Forest Regressor\": RandomForestRegressor(),\n",
        "        \"Boosting Regressor\": GradientBoostingRegressor(),\n",
        "        \"KNN Regressor\": KNeighborsRegressor(),\n",
        "        \"Logistic Regression\": LogisticRegression(),\n",
        "        \"SVM Classifier\": SVC(),\n",
        "        \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
        "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
        "        \"Boosting Classifier\": GradientBoostingClassifier(),\n",
        "        \"KNN Classifier\": KNeighborsClassifier(),\n",
        "        \"Naive Bayes Classifier\": GaussianNB(),\n",
        "    }\n",
        "\n",
        "    if model_name == \"Polynomial Regression\":\n",
        "        poly = PolynomialFeatures(degree=2)\n",
        "        X_train_poly = poly.fit_transform(X_train)\n",
        "        X_test_poly = poly.transform(X_test)\n",
        "        lin_reg = LinearRegression()\n",
        "        lin_reg.fit(X_train_poly, y_train)\n",
        "        metrics = evaluate_regression(lin_reg, X_test_poly, y_test, X_train_poly)\n",
        "        trained_model = lin_reg\n",
        "    else:\n",
        "        model = model_map[model_name]\n",
        "        model.fit(X_train, y_train)\n",
        "        if task_type == 'regression':\n",
        "            metrics = evaluate_regression(model, X_test, y_test, X_train)\n",
        "        else:\n",
        "            metrics = evaluate_classification(model, X_test, y_test, balance)\n",
        "        trained_model = model\n",
        "\n",
        "    return trained_model, metrics\n",
        "\n",
        "# Data Analysis Tab\n",
        "with tabs[0]:\n",
        "    st.header(\"Data Analysis\")\n",
        "    st.write(\"Dataset Preview:\", data.head())\n",
        "\n",
        "    y_col = st.selectbox(\"Select the target column:\", data.columns)\n",
        "    if y_col:\n",
        "        y = data[y_col]\n",
        "        unique_values = y.nunique()\n",
        "\n",
        "        # Determine if the data is continuous or discrete\n",
        "        if y.dtype in [np.int64, np.float64]:\n",
        "            if unique_values > 20:\n",
        "                inferred_task_type = 'regression'\n",
        "                data_type = \"Continuous\"\n",
        "            else:\n",
        "                inferred_task_type = 'classification'\n",
        "                data_type = \"Discrete\"\n",
        "        else:\n",
        "            inferred_task_type = 'classification'\n",
        "            data_type = \"Discrete\"\n",
        "\n",
        "        balance = inferred_task_type == 'classification' and (y.value_counts(normalize=True).max() <= 0.7)\n",
        "\n",
        "        st.write(f\"**Target Column Data Type:** {data_type}\")\n",
        "        st.write(f\"**Inferred Task Type:** {inferred_task_type}\")\n",
        "        st.write(f\"**Data Balance:** {'Balanced' if balance else 'Unbalanced'}\")\n",
        "\n",
        "        if inferred_task_type == 'regression':\n",
        "            st.write(\"**Suggested Model:** Linear Regression or Random Forest Regressor\")\n",
        "        else:\n",
        "            st.write(\"**Suggested Model:** Random Forest Classifier or Logistic Regression\")\n",
        "\n",
        "        # Display normal ranges if Indian Liver Patient dataset is selected\n",
        "        if selected_dataset_name == \"Indian Liver Patient\":\n",
        "            st.write(\"### Liver Function Test Analysis\")\n",
        "            for test, reference in liver_function_reference.items():\n",
        "                st.write(f\"- **{test}:** {reference}\")\n",
        "\n",
        "\n",
        "# Model Evaluation Tab\n",
        "with tabs[1]:\n",
        "    st.header(\"Model Evaluation\")\n",
        "    X_cols = st.multiselect(\"Select feature columns:\", [col for col in data.columns if col != y_col])\n",
        "    if not X_cols:\n",
        "        st.warning(\"Please select at least one feature column.\")\n",
        "    else:\n",
        "        X = data[X_cols]\n",
        "        y = data[y_col]\n",
        "\n",
        "        # Confirm task type\n",
        "        task_type = st.radio(\"Confirm Task Type:\", [\"regression\", \"classification\"])\n",
        "        balance = task_type == 'classification' and (y.value_counts(normalize=True).max() <= 0.7)\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Define model list based on task type\n",
        "        if task_type == 'regression':\n",
        "            model_list = [\n",
        "                \"Linear Regression\", \"Polynomial Regression\", \"Ridge Regression\", \"Lasso Regression\",\n",
        "                \"ElasticNet Regression\", \"SVM Regression\", \"Decision Tree Regressor\",\n",
        "                \"Random Forest Regressor\", \"Boosting Regressor\", \"KNN Regressor\"\n",
        "            ]\n",
        "        else:  # Classification models\n",
        "            model_list = [\n",
        "                \"Logistic Regression\", \"SVM Classifier\", \"Decision Tree Classifier\",\n",
        "                \"Random Forest Classifier\", \"Boosting Classifier\", \"KNN Classifier\",\n",
        "                \"Naive Bayes Classifier\"\n",
        "            ]\n",
        "\n",
        "        # Model selection and evaluation\n",
        "        selected_model = st.selectbox(\"Select a model to evaluate:\", model_list)\n",
        "        if st.button(\"Run Selected Model\"):\n",
        "            trained_model, metrics = apply_single_model(X_train, X_test, y_train, y_test, selected_model, task_type, balance)\n",
        "            st.session_state[\"trained_model\"] = trained_model  # Save the trained model to session state\n",
        "            st.session_state[\"X_cols\"] = X_cols  # Save selected feature columns\n",
        "\n",
        "            # Display metrics\n",
        "            st.write(f\"Model {selected_model} Performance Metrics:\")\n",
        "            for metric, value in metrics.items():\n",
        "                st.write(f\"- {metric}: {value:.2f}\")\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with tabs[2]:\n",
        "    st.header(\"Future Prediction\")\n",
        "\n",
        "    # Display liver function reference values if the dataset is \"Indian Liver Patient\"\n",
        "    if selected_dataset_name == \"Indian Liver Patient\":\n",
        "        st.write(\"### Liver Function Test Reference Ranges:\")\n",
        "        for test, reference in liver_function_reference.items():\n",
        "            st.write(f\"- **{test}:** {reference}\")\n",
        "\n",
        "    elif selected_dataset_name == \"Kidney Disease\":\n",
        "        st.write(\"### Kidney Disease Parameter Reference Ranges:\")\n",
        "        for parameter, reference in kidney_disease_reference.items():\n",
        "            st.write(f\"- **{parameter}:** {reference}\")\n",
        "\n",
        "    elif selected_dataset_name == \"Parkinsons\":\n",
        "        st.write(\"### Parkinson's Disease Parameter Reference Ranges:\")\n",
        "        for parameter, reference in parkinsons_reference.items():\n",
        "            st.write(f\"- **{parameter}:** {reference}\")\n",
        "\n",
        "    if \"trained_model\" in st.session_state and \"X_cols\" in st.session_state:\n",
        "        st.title(\"Provide data for prediction using the selected features.\")\n",
        "\n",
        "        # Generate input fields dynamically for prediction\n",
        "        input_data = {col: st.number_input(f\"Enter value for {col}:\", value=0.0, format=\"%.5f\") for col in st.session_state[\"X_cols\"]}\n",
        "        input_df = pd.DataFrame([input_data])  # Convert input to DataFrame\n",
        "        st.write(\"Input Data Preview:\", input_df)\n",
        "\n",
        "        # Define the normal ranges for liver function tests\n",
        "        liver_function_ranges = {\n",
        "            \"Age\": (18, 90),  # Normal range (years)\n",
        "            \"Gender\": (0, 1),  # 0 for female, 1 for male\n",
        "            \"Total_Bilirubin\": (0.3, 1.2),  # Normal range (mg/dL)\n",
        "            \"Direct_Bilirubin\": (0.0, 0.3),  # Normal range (mg/dL)\n",
        "            \"Alkaline_Phosphotase\": (44, 147),  # Normal range (U/L)\n",
        "            \"Alamine_Aminotransferase\": (7, 56),  # Normal range (U/L)\n",
        "            \"Aspartate_Aminotransferase\": (10, 40),  # Normal range (U/L)\n",
        "            \"Total_Protiens\": (6.0, 8.3),  # Normal range (g/dL)\n",
        "            \"Albumin\": (3.5, 5.0),  # Normal range (g/dL)\n",
        "            \"Albumin_and_Globulin_Ratio\": (1.0, 2.1)  # Normal range (ratio)\n",
        "        }\n",
        "\n",
        "        # Define numerical ranges for kidney disease parameters\n",
        "        kidney_numerical_ranges = {\n",
        "            \"age\": (0, 90),\n",
        "            \"bp\": (90, 120),\n",
        "            \"sg\": (1.010, 1.030),\n",
        "            \"al\": (0, 30),\n",
        "            \"su\": (0, 0),\n",
        "            \"bgr\": (70, 140),\n",
        "            \"bu\": (7, 20),\n",
        "            \"sc\": (0.6, 1.2),\n",
        "            \"sod\": (135, 145),\n",
        "            \"pot\": (3.5, 5.0),\n",
        "            \"hemo\": (12, 16),\n",
        "            \"pcv\": (35, 45),\n",
        "            \"wc\": (4000, 11000),\n",
        "            \"rc\": (4.5, 6.0),\n",
        "        }\n",
        "\n",
        "        # Define valid categorical values for kidney disease parameters\n",
        "        kidney_categorical_values = {\n",
        "            \"rbc\": {1: \"Normal\", 0: \"Abnormal\"},\n",
        "            \"pc\": {1: \"Normal\", 0: \"Abnormal\"},\n",
        "            \"pcc\": {0: \"Not Present\", 1: \"Present\"},\n",
        "            \"ba\": {0: \"Not Present\", 1: \"Present\"},\n",
        "            \"htn\": {0: \"No\", 1: \"Yes\"},\n",
        "            \"dm\": {0: \"No\", 1: \"Yes\"},\n",
        "            \"cad\": {0: \"No\", 1: \"Yes\"},\n",
        "            \"appet\": {1: \"Good\", 0: \"Poor\"},\n",
        "            \"pe\": {0: \"No\", 1: \"Yes\"},\n",
        "            \"ane\": {0: \"No\", 1: \"Yes\"}\n",
        "        }\n",
        "\n",
        "        parkinsons_ranges = {\n",
        "            \"MDVP:Fo(Hz)\": (85, 255),\n",
        "            \"MDVP:Fhi(Hz)\": (100, 260),\n",
        "            \"MDVP:Flo(Hz)\": (75, 240),\n",
        "            \"MDVP:Jitter(%)\": (0.0, 0.02),\n",
        "            \"MDVP:Jitter(Abs)\": (0.0, 0.0001),\n",
        "            \"MDVP:RAP\": (0.0, 0.02),\n",
        "            \"MDVP:PPQ\": (0.0, 0.02),\n",
        "            \"Jitter:DDP\": (0.0, 0.06),\n",
        "            \"MDVP:Shimmer\": (0.0, 0.03),\n",
        "            \"MDVP:Shimmer(dB)\": (0.0, 0.35),\n",
        "            \"Shimmer:APQ3\": (0.0, 0.02),\n",
        "            \"Shimmer:APQ5\": (0.0, 0.03),\n",
        "            \"MDVP:APQ\": (0.0, 0.04),\n",
        "            \"Shimmer:DDA\": (0.0, 0.09),\n",
        "            \"NHR\": (0.0, 0.3),\n",
        "            \"HNR\": (20, float('inf')),\n",
        "            \"RPDE\": (0.2, 0.6),\n",
        "            \"DFA\": (0.5, 0.8),\n",
        "            \"spread1\": (-7, -4),\n",
        "            \"spread2\": (-0.5, 0.5),\n",
        "            \"D2\": (2, 3),\n",
        "            \"PPE\": (0.0, 0.8)\n",
        "        }\n",
        "\n",
        "        # Check if the entered values are within normal ranges and store the results\n",
        "        status_comparison = []\n",
        "        for col, value in input_data.items():\n",
        "            comparison = {\n",
        "                \"Column\": col,\n",
        "                \"Value\": value,\n",
        "                \"Status\": None,\n",
        "                \"Normal Range\": None\n",
        "            }\n",
        "\n",
        "            # Handle the special case for Gender\n",
        "            if col == \"Gender\":\n",
        "                if value == 1:\n",
        "                    comparison[\"Value\"] = \"Male\"\n",
        "                elif value == 0:\n",
        "                    comparison[\"Value\"] = \"Female\"\n",
        "                comparison[\"Normal Range\"] = \"0 (Female) - 1 (Male)\"\n",
        "                comparison[\"Status\"] = \"Normal\"\n",
        "\n",
        "            elif col in kidney_categorical_values:\n",
        "                category_map = kidney_categorical_values[col]\n",
        "                if value in category_map:\n",
        "                    comparison[\"Value\"] = category_map[value]\n",
        "                    comparison[\"Normal Range\"] = \", \".join([f\"{k} ({v})\" for k, v in category_map.items()])\n",
        "                    comparison[\"Status\"] = \"Normal\"\n",
        "                else:\n",
        "                    comparison[\"Status\"] = \"Abnormal\"\n",
        "                    comparison[\"Normal Range\"] = \"Invalid Value\"\n",
        "\n",
        "            elif selected_dataset_name == \"Indian Liver Patient\" and col in liver_function_ranges:\n",
        "                min_val, max_val = liver_function_ranges[col]\n",
        "                if value < min_val:\n",
        "                    comparison[\"Status\"] = \"Low\"\n",
        "                elif value > max_val:\n",
        "                    comparison[\"Status\"] = \"High\"\n",
        "                else:\n",
        "                    comparison[\"Status\"] = \"Normal\"\n",
        "                comparison[\"Normal Range\"] = f\"{min_val} - {max_val}\"\n",
        "\n",
        "            elif selected_dataset_name == \"Kidney Disease\" and col in kidney_numerical_ranges:\n",
        "                min_val, max_val = kidney_numerical_ranges[col]\n",
        "                if value < min_val:\n",
        "                    comparison[\"Status\"] = \"Low\"\n",
        "                elif value > max_val:\n",
        "                    comparison[\"Status\"] = \"High\"\n",
        "                else:\n",
        "                    comparison[\"Status\"] = \"Normal\"\n",
        "                comparison[\"Normal Range\"] = f\"{min_val} - {max_val}\"\n",
        "\n",
        "            elif selected_dataset_name == \"Parkinsons\" and col in parkinsons_ranges:\n",
        "                min_val, max_val = parkinsons_ranges[col]\n",
        "                if value < min_val:\n",
        "                    comparison[\"Status\"] = \"Low\"\n",
        "                elif value > max_val:\n",
        "                    comparison[\"Status\"] = \"High\"\n",
        "                else:\n",
        "                    comparison[\"Status\"] = \"Normal\"\n",
        "                comparison[\"Normal Range\"] = f\"{min_val} - {max_val}\"\n",
        "\n",
        "            else:\n",
        "                comparison[\"Status\"] = \"N/A\"\n",
        "                comparison[\"Normal Range\"] = \"Not Available\"\n",
        "\n",
        "            status_comparison.append(comparison)\n",
        "\n",
        "        # Display the status comparison table\n",
        "        if status_comparison:\n",
        "            st.write(\"### Test Status Comparison:\")\n",
        "            comparison_df = pd.DataFrame(status_comparison)\n",
        "            st.dataframe(comparison_df)\n",
        "\n",
        "            # Generate countplot for the 'Status' column\n",
        "            status_series = comparison_df['Status']\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.countplot(x=status_series, palette='Set2')\n",
        "            plt.title(f\"Distribution of Test Status for {selected_dataset_name}\")\n",
        "            plt.xlabel(\"Status\")\n",
        "            plt.ylabel(\"Count\")\n",
        "            st.pyplot(plt)\n",
        "\n",
        "        # Generate prediction using the trained model\n",
        "        if st.button(\"Generate Prediction\"):\n",
        "            try:\n",
        "                trained_model = st.session_state[\"trained_model\"]\n",
        "                predictions = trained_model.predict(input_df)\n",
        "\n",
        "                if selected_dataset_name == \"Indian Liver Patient\":\n",
        "                    prediction_status = [\"Normal\" if pred == 1 else \"Abnormal\" for pred in predictions]\n",
        "                    st.write(\"Patient Status:\", prediction_status)\n",
        "\n",
        "                elif selected_dataset_name == \"Kidney Disease\":\n",
        "                    prediction_status = [\"CKD (Chronic Kidney Disease)\" if pred == 1 else \"Not CKD\" for pred in predictions]\n",
        "                    st.write(\"Patient Status:\", prediction_status)\n",
        "\n",
        "                elif selected_dataset_name == \"Parkinsons\":\n",
        "                    prediction_status = [\"Parkinson's Detected\" if pred == 1 else \"No Parkinson's\" for pred in predictions]\n",
        "                    st.write(\"Patient Status:\", prediction_status)\n",
        "\n",
        "            except Exception as e:\n",
        "                st.error(f\"An error occurred during prediction: {e}\")\n",
        "        else:\n",
        "            st.warning(\"Please evaluate a model in the 'Model Evaluation' tab before generating predictions.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcTk5_kt7v7l",
        "outputId": "2bf71123-b72a-44dd-f20e-24370d015ac0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ipv4 = !curl ipv4.icanhazip.com\n",
        "ipv4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4LXh-XkpeX2",
        "outputId": "2cfb8c85-6284-47ed-ee74-ff5ec9bc7f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['35.243.205.6']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Replace 'YOUR_AUTHTOKEN' with your actual ngrok authtoken\n",
        "ngrok.set_auth_token(\"2rI2XurhgC2fxlYDtteHntWpCJf_5b1kDx2SLmwgq8GukDEyc\")\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "!streamlit run app1.py &>/dev/null&\n",
        "\n",
        "# Create a public URL using ngrok\n",
        "try:\n",
        "    public_url = ngrok.connect(8501)\n",
        "    print(f\"Streamlit app is running at {public_url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Trying to run with localtunnel\")\n",
        "    !streamlit run app1.py &>/content/logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPnfdjk9NC5n",
        "outputId": "71a6938c-d3d9-445e-b19e-ec3706751bdb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is running at NgrokTunnel: \"https://96b6-34-123-255-201.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQ9Ki8QFpO-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}